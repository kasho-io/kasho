import { Cards, Callout } from "nextra/components";

# Welcome to Kasho

Kasho solves the age-old problem of "production-like data" for staging, testing, and development environments. It supports **PostgreSQL** and **MySQL** databases, tapping into their native replication capabilities (logical replication for PostgreSQL, binary log for MySQL) and putting a transformer in the middle.

## What is Kasho?

Kasho consists of two main components working together:

- **Change Stream Service** - Captures changes from your database (`pg-change-stream` for PostgreSQL, `mysql-change-stream` for MySQL)
- **`translicator`** - Applies changes to target databases with optional transformations

Under the hood, **Redis** is used for reliable, ordered message buffering.

## Key Features

### ðŸš€ Live, Hot, Compliant Replicas

Stream database changes with minimal latency using native replication (PostgreSQL logical replication or MySQL binary log), including both DDL and DML operations. Your replicas stay in sync automatically.

### ðŸ”’ Data Transformation

Transform sensitive data with configurable rules before writing to the replica. Perfect for creating GDPR-compliant development environments from production data.

### ðŸ“¦ Simple Deployment

Deploy with Docker using a single image containing all components. Available from Docker Hub at `kashoio/kasho`. Works with Kubernetes, ECS, or any container orchestration platform.

### âš¡ Bootstrap Support

Get up and running with existing data and zero downtime using the included bootstrap process. Seamlessly migrate petabytes of data without missing a single change.

## Getting Started

<Callout type="info">Kasho requires PostgreSQL 15+ with logical replication enabled, or MySQL 8.0+ with binary logging enabled</Callout>

Ready to get started? Check out the [Quick Start Guide](/quick-start) to deploy Kasho with Docker Compose.
