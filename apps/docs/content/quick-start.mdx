import { Callout, Tabs } from "nextra/components";

# Quick Start

This guide will help you understand Kasho's architecture and get it running in your environment. While we use Docker Compose as an example, the concepts apply to any production orchestration system like Kubernetes.

## Production Deployment Overview

Kasho consists of three required containers that work together:

1. **Redis** - Used for distributed state management and caching
2. **Change Stream Service** - Captures changes from your source database (`pg-change-stream` for PostgreSQL, `mysql-change-stream` for MySQL)
3. **translicator** - Applies transformations and writes to your target database

<Callout type="info">
  **Production Environments** Most production deployments use Kubernetes, ECS, or similar orchestration systems. The
  Docker Compose example below illustrates how the containers interact and can be adapted to your specific environment.
</Callout>

### Container Images

All Kasho components are packaged in a single Docker image available from Docker Hub:

- Image: `kashoio/kasho:latest` (or specific version like `v0.3.0`)
- Commands: `./pg-change-stream`, `./mysql-change-stream`, and `./translicator`

## Prerequisites

<Callout type="warning">
  **Important: Single Translicator Only**

Currently, only a single `translicator` instance is supported. Multiple translicators would process the same changes multiple times.

</Callout>

Before you begin, ensure you have:

- A Redis instance (or Redis-compatible service)
- Container orchestration system (Kubernetes, ECS, Docker, etc.)

<Tabs items={['PostgreSQL', 'MySQL']}>
<Tabs.Tab>
- PostgreSQL 15+ databases (source and target)
- Databases configured with `wal_level = logical`

<Callout type="warning">
  **PostgreSQL WAL Level Configuration** Check your current WAL level: ```sql SHOW wal_level; ``` If it's not `logical`,
  update your `postgresql.conf`: ``` wal_level = logical ``` **Important**: After changing this setting, you must
  restart PostgreSQL for it to take effect.
</Callout>
</Tabs.Tab>
<Tabs.Tab>
- MySQL 8.0+ databases (source and target)
- Binary logging enabled with ROW format and GTID mode

<Callout type="warning">
  **MySQL Binary Log Configuration** Check your current binlog settings: ```sql SELECT @@binlog_format, @@log_bin, @@gtid_mode; ```
  If binlog is not enabled, add to your `my.cnf`:
  ```ini
  [mysqld]
  server-id = 1
  log_bin = mysql-bin
  binlog_row_image = FULL
  gtid_mode = ON
  enforce_gtid_consistency = ON
  ```
  **Important**: After changing these settings, you must restart MySQL for them to take effect.
</Callout>
</Tabs.Tab>
</Tabs>

## Docker Compose Example

<Callout type="info">
  **Example Configuration** The following Docker Compose configuration demonstrates how Kasho's containers interact.
  Adapt this to your production orchestration system (Kubernetes manifests, ECS task definitions, etc.).
</Callout>

### Step 1: Example Directory Structure

For this example, create a directory structure:

```bash
mkdir kasho-example
cd kasho-example
```

### Step 2: Example Docker Compose Configuration

Create a `docker-compose.yml` file:

<Callout type="info">
  **Port Conflicts** If you have other services running locally, you may need to change the exposed ports. For example,
  change `"6379:6379"` to `"6380:6379"` if Redis is already running. The second number is the container's internal port
  and should not be changed.
</Callout>

<Tabs items={['PostgreSQL', 'MySQL']}>
<Tabs.Tab>
```yaml
services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data

  pg-change-stream:
    image: kashoio/kasho:latest
    command: /app/bin/pg-change-stream
    environment:
      KV_URL: redis://redis:6379
      PRIMARY_DATABASE_URL: ${PRIMARY_DATABASE_URL}
    ports:
      - "50051:50051"
    depends_on:
      - redis

  translicator:
    image: kashoio/kasho:latest
    command: /app/bin/translicator
    environment:
      CHANGE_STREAM_SERVICE_ADDR: pg-change-stream:50051
      REPLICA_DATABASE_URL: ${REPLICA_DATABASE_URL}
    volumes:
      - ./config:/app/config:ro # Contains transforms.yml
    depends_on:
      - pg-change-stream

volumes:
  redis-data:
```
</Tabs.Tab>
<Tabs.Tab>
```yaml
services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data

  mysql-change-stream:
    image: kashoio/kasho:latest
    command: /app/bin/mysql-change-stream
    environment:
      KV_URL: redis://redis:6379
      PRIMARY_DATABASE_URL: ${PRIMARY_DATABASE_URL}
    ports:
      - "50051:50051"
    depends_on:
      - redis

  translicator:
    image: kashoio/kasho:latest
    command: /app/bin/translicator
    environment:
      CHANGE_STREAM_SERVICE_ADDR: mysql-change-stream:50051
      REPLICA_DATABASE_URL: ${REPLICA_DATABASE_URL}
    volumes:
      - ./config:/app/config:ro # Contains transforms.yml
    depends_on:
      - mysql-change-stream

volumes:
  redis-data:
```
</Tabs.Tab>
</Tabs>

### Step 3: Configuration Files

Create a `config` directory for your transforms:

```bash
mkdir config
```

Create `config/transforms.yml` with your transformation rules:

```yaml
version: v1
tables:
  # Example: Transform user emails in the public.users table
  public.users:
    email: FakeEmail
    phone: FakePhone
```

See the [Transform Configuration](/configuration/transforms) guide for all available transforms.

### Step 4: Environment Variables

Create a `.env` file with your database connections and service configuration.

<Callout type="warning">
  **Important**: Replace the example database URLs below with your actual connection strings. The services
  will not start successfully without valid database connections.
</Callout>

<Tabs items={['PostgreSQL', 'MySQL']}>
<Tabs.Tab>
```bash
# Source database (read-only access needed)
# Replace with your actual source database connection string
PRIMARY_DATABASE_URL=postgresql://kasho:password@source-host:5432/source_db?sslmode=disable

# Target database (write access needed)
# Replace with your actual target database connection string
REPLICA_DATABASE_URL=postgresql://kasho:password@target-host:5432/target_db?sslmode=disable

# Redis connection
KV_URL=redis://redis:6379

# Change stream service for translicator
CHANGE_STREAM_SERVICE_ADDR=pg-change-stream:50051
```
</Tabs.Tab>
<Tabs.Tab>
```bash
# Source database (read-only access needed)
# Replace with your actual source database connection string
PRIMARY_DATABASE_URL=mysql://kasho:password@source-host:3306/source_db?tls=false

# Target database (write access needed)
# Replace with your actual target database connection string
REPLICA_DATABASE_URL=mysql://kasho:password@target-host:3306/target_db?tls=false

# Redis connection
KV_URL=redis://redis:6379

# Change stream service for translicator
CHANGE_STREAM_SERVICE_ADDR=mysql-change-stream:50051
```
</Tabs.Tab>
</Tabs>

<Callout type="info">
  **Production Note** In production, these service URLs will depend on your infrastructure. For example, in Kubernetes
  you might use service names like `redis.default.svc.cluster.local:6379`.
</Callout>

### Step 5: Run the Example

```bash
docker-compose up -d
```

Verify all services are running:

```bash
docker-compose ps
```

You should see:

- `redis` - Running
- `pg-change-stream` or `mysql-change-stream` - Running on port 50051
- `translicator` - Running

## Production Considerations

When deploying to production:

1. **Container Orchestration**: Translate the Docker Compose configuration to your platform:
   - Kubernetes: Create Deployments, Services, and ConfigMaps
   - ECS: Define Task Definitions and Services
   - Other platforms: Follow your standard container deployment practices

2. **Redis**: Use a managed Redis service or ensure high availability

3. **Networking**: Ensure containers can communicate:
   - `translicator` must reach `pg-change-stream` service
   - Both services need access to their respective databases
   - Consider service discovery mechanisms in your environment

4. **Configuration Management**: Mount transform configurations using your platform's methods:
   - Kubernetes: ConfigMaps or Secrets
   - ECS: Parameter Store or S3
   - Docker: Volume mounts or config management tools

## Bootstrap Existing Data

If you have existing data in your source database, you'll need to run the bootstrap process:

<Callout type="info">
  The bootstrap process ensures zero data loss by capturing changes during the initial data load
</Callout>

<Tabs items={['PostgreSQL', 'MySQL']}>
<Tabs.Tab>
1. Execute the bootstrap process in the pg-change-stream container:

```bash
# Run bootstrap process (will prompt for confirmation)
docker exec -it kasho-example-pg-change-stream-1 /app/scripts/bootstrap-kasho-pg.sh
```

<Callout type="info">
  **Container Name** The container name may vary based on your setup. Use `docker ps` to find the exact name of your
  pg-change-stream container.
</Callout>
</Tabs.Tab>
<Tabs.Tab>
1. Execute the bootstrap process in the mysql-change-stream container:

```bash
# Run bootstrap process (will prompt for confirmation)
docker exec -it kasho-example-mysql-change-stream-1 /app/scripts/bootstrap-kasho-mysql.sh
```

<Callout type="info">
  **Container Name** The container name may vary based on your setup. Use `docker ps` to find the exact name of your
  mysql-change-stream container.
</Callout>
</Tabs.Tab>
</Tabs>

2. The bootstrap process will:
   - Create a consistent snapshot of your source database
   - Start capturing changes from that point
   - Load the snapshot data
   - Transition to streaming mode

If you prefer, you can manually bootstrap things with a bit more effort. See the [Bootstrap Process](/installation/bootstrap) guide for detailed information.

## Verify Installation

Check that replication is working:

1. **Check change-stream service status (using gRPC):**

   ```bash
   # Using grpcurl (install with: brew install grpcurl)
   grpcurl -plaintext localhost:50051 change_stream.ChangeStream/GetStatus
   ```

2. **View logs:**

<Tabs items={['PostgreSQL', 'MySQL']}>
<Tabs.Tab>
   ```bash
   docker-compose logs -f pg-change-stream
   docker-compose logs -f translicator
   ```
</Tabs.Tab>
<Tabs.Tab>
   ```bash
   docker-compose logs -f mysql-change-stream
   docker-compose logs -f translicator
   ```
</Tabs.Tab>
</Tabs>

3. **Make a test change in your source database:**

   ```sql
   -- In your source database
   UPDATE users SET updated_at = NOW() WHERE id = 1;
   ```

4. **Verify the change appears in your target database**

## Next Steps

- [Configure your databases](/installation/database-setup) for production use
- [Understand configuration options](/installation/configuration)
- [Learn about transforms](/configuration/transforms)

## Troubleshooting

**Services won't start:**

- Ensure your environment variables are set correctly, especially the database URLs.
- Verify `transforms.yml` exists in the config directory
- Check logs: `docker-compose logs [service-name]`

**Connection errors:**

- Ensure databases are accessible from Docker containers
- For PostgreSQL: Verify `wal_level = logical`
- For MySQL: Verify binary logging is enabled with `SHOW VARIABLES LIKE 'log_bin'`
- Check firewall rules allow connections
